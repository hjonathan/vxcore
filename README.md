# VXCore - Gemini API Server

Un servidor Node.js Express para hacer consultas a la API de Google Gemini AI usando la nueva librer√≠a `@google/genai`.

## Caracter√≠sticas

- ü§ñ Integraci√≥n con Google's Generative AI (Gemini) usando `@google/genai`
- üí¨ Endpoint de chat para generaci√≥n de texto
- üåä Endpoint de streaming para respuestas en tiempo real
- üó£Ô∏è Endpoint de conversaci√≥n multi-turno
- üëÅÔ∏è Endpoint de an√°lisis de im√°genes (visi√≥n)
- üìã Endpoint para listar modelos disponibles
- üè• Endpoint de health check
- üîí Configuraci√≥n con variables de entorno
- üõ°Ô∏è CORS habilitado para requests cross-origin
- ‚ö° Manejo de errores y validaci√≥n

## Setup

### 1. Instalar Dependencias

```bash
npm install
```

### 2. Configuraci√≥n del Entorno

Copia la plantilla de entorno y agrega tu API key de Gemini:

```bash
cp env.example .env
```

Edita `.env` y agrega tu API key de Gemini:
```
GEMINI_API_KEY=tu_api_key_aqui
PORT=3000
```

### 3. Obtener API Key de Gemini

1. Ve a [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crea una nueva API key
3. Copia la key a tu archivo `.env`

### 4. Ejecutar el Servidor

**Modo desarrollo (con auto-restart):**
```bash
npm run dev
```

**Modo producci√≥n:**
```bash
npm start
```

**Ejecutar el ejemplo simple:**
```bash
npm run start:main
```

El servidor iniciar√° en `http://localhost:3000` (o el PORT especificado en tu .env).

## Endpoints de la API

### Health Check
```
GET /health
```
Retorna el estado del servidor y timestamp.

**Respuesta:**
```json
{
  "status": "OK",
  "message": "Gemini API Server is running",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

### Chat
```
POST /chat
```
Env√≠a un mensaje a Gemini y obt√©n una respuesta.

**Request Body:**
```json
{
  "message": "Hola, ¬øc√≥mo est√°s?",
  "model": "gemini-2.5-flash"  // opcional, por defecto gemini-2.5-flash
}
```

**Respuesta:**
```json
{
  "success": true,
  "response": "¬°Hola! Estoy bien, gracias por preguntar...",
  "model": "gemini-2.5-flash",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

### Streaming Chat
```
POST /chat/stream
```
Obt√©n una respuesta streaming de Gemini (generaci√≥n de texto en tiempo real).

**Request Body:**
```json
{
  "message": "Cu√©ntame una historia",
  "model": "gemini-2.5-flash"  // opcional, por defecto gemini-2.5-flash
}
```

**Respuesta:** Transmite chunks de texto directamente al cliente.

### Conversaci√≥n Multi-turno
```
POST /conversation
```
Mant√©n una conversaci√≥n con historial de mensajes.

**Request Body:**
```json
{
  "messages": [
    {
      "role": "user",
      "parts": [{ "text": "Hola, ¬øc√≥mo te llamas?" }]
    },
    {
      "role": "model",
      "parts": [{ "text": "Me llamo Gemini, ¬øen qu√© puedo ayudarte?" }]
    },
    {
      "role": "user",
      "parts": [{ "text": "¬øPuedes explicarme qu√© es la IA?" }]
    }
  ],
  "model": "gemini-2.5-flash"  // opcional
}
```

**Respuesta:**
```json
{
  "success": true,
  "response": "La inteligencia artificial (IA) es...",
  "model": "gemini-2.5-flash",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

### An√°lisis de Im√°genes (Visi√≥n)
```
POST /vision
```
Analiza im√°genes con texto descriptivo.

**Request Body:**
```json
{
  "message": "¬øQu√© hay en esta imagen?",
  "imageData": "base64_encoded_image_data",
  "model": "gemini-2.5-flash"  // opcional
}
```

**Respuesta:**
```json
{
  "success": true,
  "response": "En esta imagen veo...",
  "model": "gemini-2.5-flash",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

### Modelos Disponibles
```
GET /models
```
Obt√©n una lista de modelos disponibles de Gemini.

**Respuesta:**
```json
{
  "success": true,
  "models": [...]
}
```

## Ejemplos de Uso

### Usando curl

**Health check:**
```bash
curl http://localhost:3000/health
```

**Chat request:**
```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "¬øCu√°l es la capital de Francia?"}'
```

**Streaming chat:**
```bash
curl -X POST http://localhost:3000/chat/stream \
  -H "Content-Type: application/json" \
  -d '{"message": "Escribe un poema corto sobre programaci√≥n"}'
```

**Conversaci√≥n:**
```bash
curl -X POST http://localhost:3000/conversation \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "parts": [{"text": "Hola"}]},
      {"role": "model", "parts": [{"text": "¬°Hola! ¬øEn qu√© puedo ayudarte?"}]},
      {"role": "user", "parts": [{"text": "¬øQu√© es la programaci√≥n?"}]}
    ]
  }'
```

### Usando JavaScript/Fetch

```javascript
// Chat regular
const response = await fetch('http://localhost:3000/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: 'Explica la computaci√≥n cu√°ntica en t√©rminos simples'
  })
});

const data = await response.json();
console.log(data.response);

// Streaming chat
const streamResponse = await fetch('http://localhost:3000/chat/stream', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: 'Escribe una historia sobre un robot'
  })
});

const reader = streamResponse.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  console.log(chunk);
}

// Conversaci√≥n
const conversationResponse = await fetch('http://localhost:3000/conversation', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    messages: [
      { role: 'user', parts: [{ text: 'Hola' }] },
      { role: 'model', parts: [{ text: '¬°Hola! ¬øC√≥mo est√°s?' }] },
      { role: 'user', parts: [{ text: 'Bien, ¬øy t√∫?' }] }
    ]
  })
});

const conversationData = await conversationResponse.json();
console.log(conversationData.response);
```

## Manejo de Errores

El servidor incluye manejo comprehensivo de errores:

- **400 Bad Request**: Campos requeridos faltantes
- **500 Internal Server Error**: Errores de API o API key faltante
- **404 Not Found**: Endpoints inv√°lidos

Todos los errores retornan respuestas JSON con detalles del error.

## Variables de Entorno

| Variable | Descripci√≥n | Default |
|----------|-------------|---------|
| `GEMINI_API_KEY` | Tu API key de Gemini | Requerido |
| `PORT` | Puerto del servidor | 3000 |

## Modelos Disponibles

- `gemini-2.5-flash`: Modelo de prop√≥sito general (m√°s r√°pido)
- `gemini-2.5-pro`: Modelo m√°s avanzado
- `gemini-2.0-flash-exp`: Modelo experimental

## Notas de Seguridad

- Nunca commits tu archivo `.env` al control de versiones
- El archivo `.env` ya est√° en `.gitignore`
- Usa variables de entorno para configuraci√≥n sensible
- CORS est√° habilitado para desarrollo - configura apropiadamente para producci√≥n

## Desarrollo

Para ejecutar en modo desarrollo con auto-restart:
```bash
npm run dev
```

Esto usa nodemon para reiniciar autom√°ticamente el servidor cuando los archivos cambien.

## Licencia

ISC 